---
title: Tool Compatibility
description: "How to structure your tools for Raysurfer caching"
---

<Warning>
  Raysurfer is designed for agents that generate code and execute it in production. If your agent isn't doing that yet, you need to get onboard! Until then, Raysurfer is not for you.
</Warning>

## When Raysurfer Works Best

Raysurfer is optimal when your tools have **typed, structured outputs** as both their inputs and outputs. This lets cached code confidently access fields, call downstream tools, and compose multi-step workflows without ambiguity.

If your tools pass **unstructured strings** between each other, that's fine—as long as your agent doesn't need the LLM to read or interpret those values between tool calls. For example, passing an opaque ID string from one tool to the next works perfectly because the code just forwards the value without inspecting it.

However, if your agent relies on the LLM to **read and reason about unstructured intermediate values** between tool calls—deciding what to do next based on free-text output, parsing natural language responses, or branching on string content—you are better off using an iterative agent. Raysurfer caches the generated code block as a whole, so it can't replay workflows where the LLM needs to make decisions mid-execution based on unstructured data.

## The Requirement

For Raysurfer to cache and replay your agent's outputs, **tools must be exposed as functions that can be called directly from code**.

This means your agent's tool implementations should be:
- Pure functions with clear inputs and outputs
- Pure functions with clear, typed inputs and outputs—avoid `unknown`, `any`, or `Dict[str, Any]` types. The more specific your type annotations, the better the agent's code generation will perform.
- Callable without side effects on the LLM context
- Composable into multi-step workflows

## The Ideal Pattern

The best way to understand Raysurfer's value is through this pattern:

```python
llm_input = params
out1 = query_customer_records_from_postgres_database(llm_input)
out2 = lookup_contact_details_in_local_csv_file(out1[2])
out3 = fetch_purchase_history_from_stripe_api(out2.files[-1])
out4 = calculate_loyalty_tier_from_transaction_count(out3.length)

return out4
```

This is a multi-step workflow where each step depends on the previous step's output. When your agent generates this code:

1. **First run**: The LLM generates this code, executes it, and Raysurfer caches the entire block
2. **Second run**: Raysurfer retrieves the cached code and executes it directly—no LLM iteration needed

### Why This Is Optimal

Without Raysurfer, the agent must iterate through the LLM multiple times: generating the code, checking if it compiles, running it, handling errors, and retrying. Each iteration costs tokens and time.

With Raysurfer, the agent already knows from previous runs exactly how this code executed. It doesn't need to:

- **Generate the code** — it's already cached
- **Verify it will run correctly** — previous executions prove it works
- **Handle edge cases** — the cached version already handles them

This eliminates the trial-and-error loop entirely. Instead of multiple LLM roundtrips to build and validate the code, the agent retrieves proven code and executes it immediately.

More importantly, Raysurfer ensures the output is actually useful to the user. Code that runs without errors isn't enough—what matters is that the output solves the user's problem. Raysurfer's verdict scoring system tracks whether outputs were genuinely helpful, not just whether they executed successfully. Cached code that produces useful results rises to the top; code that technically works but doesn't help gets deprioritized.

## Why Functions Matter

Raysurfer caches the **code** your agent generates, not the raw outputs. For this to work, your tools must be:

| Requirement | Why It Matters |
|-------------|----------------|
| **Callable from code** | Cached code needs to execute the same functions |
| **Deterministic with same inputs** | Replayed code should produce consistent results |
| **Exposed as importable functions** | The generated code needs to reference real functions |
| **Strongly typed** | Specific types help the agent generate correct, reusable code |

## Why Typing Matters

The more specific your type annotations, the better the agent's code generation will perform. Avoid generic types like `unknown`, `any`, `object`, or `Dict[str, Any]`—these force the agent to guess at data structures, leading to brittle code that doesn't cache well.

<CodeGroup>

```python Good - Specific types
from dataclasses import dataclass

@dataclass
class SalesRecord:
    id: str
    amount: float
    quarter: str
    region: str

@dataclass
class Report:
    title: str
    records: list[SalesRecord]
    total: float

def generate_report(records: list[SalesRecord], template: str) -> Report:
    ...
```

```python Bad - Vague types
def generate_report(records: list[dict], template: str) -> dict:
    # Agent doesn't know the shape of records or return value
    ...

def process_data(data: Any) -> Any:
    # Impossible to generate correct downstream code
    ...
```

</CodeGroup>

When types are specific, the agent generates code that correctly accesses fields like `record.amount` instead of guessing with `record["amount"]` or `record.get("amount", 0)`.

## Example: Good vs Bad

<CodeGroup>

```python Good - Functions callable from code
from my_tools import fetch_data, transform, save_result

# Agent generates this code
data = fetch_data(query="quarterly sales")
transformed = transform(data, format="csv")
result = save_result(transformed, path="/reports/q1.csv")
```

```python Bad - Interactive or stateful tools
# Can't cache this - relies on runtime state
response = llm.ask_followup("What format do you want?")
# Can't cache this - side effects in tool execution
tool.execute_with_context(current_session)
```

</CodeGroup>

## Setting Up Your Tools

To make your agent Raysurfer-compatible:

<Steps>
  <Step title="Expose tools as functions">
    Each tool should be a standalone function that takes inputs and returns outputs.
  </Step>
  <Step title="Make inputs explicit">
    All data the function needs should come from parameters, not global state.
  </Step>
  <Step title="Return structured outputs">
    Functions should return data that can be passed to subsequent function calls.
  </Step>
</Steps>

## Real-World Example

Here's a practical example of a Raysurfer-compatible agent workflow:

```python
from data_tools import query_database, filter_records, generate_report, send_email

# This entire block gets cached and replayed
records = query_database(table="sales", quarter="Q1")
filtered = filter_records(records, min_value=10000)
report = generate_report(filtered, template="executive_summary")
result = send_email(report, recipients=["team@company.com"])

return result
```

When the same query pattern is detected, Raysurfer retrieves this code block and executes it directly—skipping token generation entirely.
