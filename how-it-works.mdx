---
title: How It Works
description: "The code cache powering AI maintained skills for vertical agents"
---

{/* old description: "The code cache powering Stack Overflow for AI agents" */}
{/* old description: "The code cache powering the code reputation layer for AI agents" */}

{/* old: ## The Stack Overflow Analogy */}
{/* old: ## The Code Reputation Layer */}
## AI Maintained Skills

{/* old: Think about how developers use Stack Overflow: they search for their problem, find an answer that already works, and use it. They don't solve every problem from scratch. */}
{/* old: Raysurfer is a code reputation layer — every snippet earns a reputation through community voting and execution results. Think of it like Stack Overflow: developers search for their problem, find an answer that already works, and use it. Raysurfer gives agents the same workflow. */}
Raysurfer provides AI maintained skills for vertical agents — re-use verified code from prior runs rather than serial tool calls or generating code per execution. Every snippet earns a reputation through community voting and execution results, so the best code rises to the top.

Raysurfer works the same way for AI agents:

```
Without Raysurfer:  Task → Agent generates code from scratch → Runs it
With Raysurfer:     Task → Agent searches for proven code → Runs it (instant)
```

Queries don't need to be identical — Raysurfer uses semantic matching to find related patterns. "Fetch user data from the API" and "Get customer info from the endpoint" return the same proven code.

## Under the Hood: Semantic Code Cache

The mechanism behind this is a **semantic code cache**. When your agent generates code that works, Raysurfer caches it with semantic embeddings. When a similar task comes up later — from you or from the community — the proven code is retrieved instead of regenerated.

You don't need to manage anything. Caching and retrieval happen automatically.

## Why This Works

Production agents in 2026 are running longer and longer. Multi-step workflows, complex tool chains, sprawling context windows. They're becoming difficult to context manage and behave consistently.

But here's the thing: **the median run has a typical shape.**

{/* old: Despite all the complexity, most runs follow similar patterns. Just like Stack Overflow answers cover the common patterns developers hit, Raysurfer captures the common patterns agents hit and serves proven code for them. */}
{/* old: Despite all the complexity, most runs follow similar patterns. Raysurfer's code reputation layer captures these common patterns and serves proven, battle-tested code — much like how the best Stack Overflow answers surface for common developer problems. */}
Despite all the complexity, most runs follow similar patterns. Raysurfer captures these common patterns as AI maintained skills — verified code from prior runs that your agent reuses instead of regenerating.

This gives you:

- **Better context management** — intermediate outputs between API calls or code functions aren't printed by default, keeping context clean
- **Consistent behavior** — the model starts from proven code instead of improvising each time
- **Faster execution** — skip the generation, go straight to the result

## What Gets Cached

Raysurfer automatically caches:

- Code outputs from your agent
- Generated documents and templates
- Structured data transformations

You don't need to tag or categorize anything. Raysurfer uses semantic matching to find similar past outputs.

## Quality Over Time

Raysurfer tracks which cached outputs work well:

- Outputs that succeed get prioritized
- Outputs that fail get deprioritized
- The system improves automatically

## Verified Snippets

Every cached output is verified before reuse:

- Only successful executions get cached
- Failed outputs are automatically excluded
- Your agent builds a library of proven code over time

## Immutable Snippets

Code snippets in Raysurfer are immutable—they cannot be edited after creation. When you need a modified version of existing code, a new snippet is created instead.

This means:

- **Edits create new snippets** — modifying cached code doesn't overwrite the original; it creates a new entry that surfaces for different types of requests
- **Original code stays intact** — the original snippet remains available with its existing verdict scores
- **Version history is automatic** — each iteration of a code pattern becomes its own snippet, and the best-performing version rises to the top through voting

This design provides:

- **Auditability** — complete history of all cached code
- **Reproducibility** — retrieval results are consistent over time
- **Quality tracking** — verdict scores stay tied to the exact code that earned them

You can view all your snippets in the [dashboard](https://raysurfer.com/dashboard).

## Snippet Scoring

Every snippet has a verdict score that determines its priority in retrieval.

### Automatic Voting

The system automatically votes in two scenarios:

- **On cache reuse** — when cached code runs successfully and produces the expected output, it receives a thumbs up; failures receive a thumbs down
- **On upload** — when new code is stored after a successful execution, Raysurfer's AI evaluates and votes on it (controlled by `use_raysurfer_ai_voting`, on by default). You can also provide your own votes via `user_vote` / `user_votes`, which skips AI voting.

Both happen in the background after each execution—you don't need to do anything. The SDK also captures execution logs (tool outputs) and sends them to the backend as context for voting.

### Manual Voting

You can also manually adjust scores in the [dashboard](https://raysurfer.com/dashboard):

- Add positive score to promote high-quality snippets
- Add negative score to demote problematic code
- Override automatic votes when you know better than the AI

The verdict score is calculated as:

```
verdict_score = thumbs_up / (thumbs_up + thumbs_down)
```

Snippets with higher verdict scores are prioritized during retrieval, ensuring your agent uses the most reliable code.

## Well-Documented Tool Schemas

For cached code to be reusable, the tool functions it calls must have well-documented input and output schemas. This lets agents extract specific properties (accessors) from one tool's response to pass into the next.

```python
# Good: Agent can extract user.email for the next call
class UserResponse:
    id: str           # Unique user identifier
    email: str        # User's email address
    created_at: str   # ISO 8601 timestamp

# Bad: Agent doesn't know what's inside
def get_user(id: str) -> dict:
    ...
```

Well-typed responses enable:

- **Property extraction** — agents can access `.email` or `.id` from responses
- **Chained tool calls** — output from one tool feeds directly into the next
- **Better cache hits** — semantic matching works on structured, documented schemas

Here's an example of chained tool calls where each output feeds into the next:

```python
llm_input = params
out1 = query_customer_records_from_postgres_database(llm_input)
out2 = lookup_contact_details_in_local_csv_file(out1[2])
out3 = fetch_purchase_history_from_stripe_api(out2.files[-1])
out4 = calculate_loyalty_tier_from_transaction_count(out3.length)

return out4
```

Each function extracts specific properties from the previous result—`out1[2]`, `out2.files[-1]`, `out3.length`—demonstrating why well-documented schemas matter for cache reuse.

## Public Snippets — The Community Registry

{/* old: Just like Stack Overflow's value comes from community answers, Raysurfer maintains a public registry of validated code patterns sourced from popular open-source GitHub repositories. These are community-contributed answers that any agent can search and use. */}
{/* old: The code reputation layer extends to a public registry of validated code patterns sourced from popular open-source GitHub repositories. Like Stack Overflow's community answers, these are community-contributed patterns that any agent can search and use. */}
The skills library extends to a public registry of validated code patterns sourced from popular open-source GitHub repositories. These are community-contributed skills that any agent can search and use.

Enable public snippets by setting `public_snips` in the SDK constructor:

<CodeGroup>

```python Python
from raysurfer import RaySurfer

client = RaySurfer(api_key="your_key", public_snips=True)
result = client.search(task="Parse CSV and generate chart")
```

```typescript TypeScript
import { RaySurfer } from "raysurfer";

const client = new RaySurfer({ apiKey: "your_key", publicSnips: true });
const result = await client.search({ task: "Parse CSV and generate chart" });
```

</CodeGroup>

Public snippets are read-only — they cannot be edited or deleted by users. They are curated by the Raysurfer team and ranked alongside your private snippets using the same voting system — the best answers rise to the top.

Also available via the [CLI](/integrations/cli) (`--public` flag) and [MCP server](/integrations/mcp) (`public_snips` parameter).
