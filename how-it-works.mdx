---
title: How It Works
description: "The magic behind Raysurfer's speed"
---

## The Simple Version

When your agent runs a task it's done before, Raysurfer returns the cached result instantly instead of regenerating it.

```
First run:  Your query → Code generated → Result cached → Code retrieved
Second run: Your query → Cache hit → Code retrieved (instant)
```

That's it. You don't need to manage anything.

## Why This Works

Production agents in 2026 are running longer and longer. Multi-step workflows, complex tool chains, sprawling context windows. They're becoming difficult to context manage and behave consistently.

But here's the thing: **the median run has a typical shape.**

Despite all the complexity, most runs follow similar patterns. Raysurfer captures these patterns and guides the model to execute from the median run's starting point—editing that code file rather than regenerating it from scratch.

This gives you:

- **Better context management** — intermediate outputs between API calls or code functions aren't printed by default, keeping context clean
- **Consistent behavior** — the model starts from proven code instead of improvising each time
- **Faster execution** — skip the generation, go straight to the result

## What Gets Cached

Raysurfer automatically caches:

- Code outputs from your agent
- Generated documents and templates
- Structured data transformations

You don't need to tag or categorize anything. Raysurfer uses semantic matching to find similar past outputs.

## Quality Over Time

Raysurfer tracks which cached outputs work well:

- Outputs that succeed get prioritized
- Outputs that fail get deprioritized
- The system improves automatically

## Verified Snippets

Every cached output is verified before reuse:

- Only successful executions get cached
- Failed outputs are automatically excluded
- Your agent builds a library of proven code over time

## Immutable Snippets

Code snippets in Raysurfer are immutable—they cannot be edited after creation. When you need a modified version of existing code, a new snippet is created instead.

This means:

- **Edits create new snippets** — modifying cached code doesn't overwrite the original; it creates a new entry that surfaces for different types of requests
- **Original code stays intact** — the original snippet remains available with its existing verdict scores
- **Version history is automatic** — each iteration of a code pattern becomes its own snippet, and the best-performing version rises to the top through voting

This design provides:

- **Auditability** — complete history of all cached code
- **Reproducibility** — retrieval results are consistent over time
- **Quality tracking** — verdict scores stay tied to the exact code that earned them

You can view all your snippets in the [dashboard](https://raysurfer.com/dashboard).

## Snippet Scoring

Every snippet has a verdict score that determines its priority in retrieval.

### Automatic Voting

The AI system automatically votes on each code execution:

- **Success** — when cached code runs successfully and produces the expected output, it receives a thumbs up
- **Failure** — when cached code fails or produces incorrect output, it receives a thumbs down

This happens automatically in the background after each execution—you don't need to do anything.

### Manual Voting

You can also manually adjust scores in the [dashboard](https://raysurfer.com/dashboard):

- Add positive score to promote high-quality snippets
- Add negative score to demote problematic code
- Override automatic votes when you know better than the AI

The verdict score is calculated as:

```
verdict_score = thumbs_up / (thumbs_up + thumbs_down)
```

Snippets with higher verdict scores are prioritized during retrieval, ensuring your agent uses the most reliable code.

## Well-Documented Tool Schemas

For cached code to be reusable, the tool functions it calls must have well-documented input and output schemas. This lets agents extract specific properties (accessors) from one tool's response to pass into the next.

```python
# Good: Agent can extract user.email for the next call
class UserResponse:
    id: str           # Unique user identifier
    email: str        # User's email address
    created_at: str   # ISO 8601 timestamp

# Bad: Agent doesn't know what's inside
def get_user(id: str) -> dict:
    ...
```

Well-typed responses enable:

- **Property extraction** — agents can access `.email` or `.id` from responses
- **Chained tool calls** — output from one tool feeds directly into the next
- **Better cache hits** — semantic matching works on structured, documented schemas

Here's an example of chained tool calls where each output feeds into the next:

```python
llm_input = params
out1 = query_customer_records_from_postgres_database(llm_input)
out2 = lookup_contact_details_in_local_csv_file(out1[2])
out3 = fetch_purchase_history_from_stripe_api(out2.files[-1])
out4 = calculate_loyalty_tier_from_transaction_count(out3.length)

return out4
```

Each function extracts specific properties from the previous result—`out1[2]`, `out2.files[-1]`, `out3.length`—demonstrating why well-documented schemas matter for cache reuse.
