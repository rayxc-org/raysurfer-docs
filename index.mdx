---
title: Introduction
description: "AI maintained skills for vertical agents"
---

# What is Raysurfer?

Raysurfer provides **AI maintained skills for vertical agents**. Your agent stores scripts from prior runs, searches them semantically, and reuses what worked — instead of regenerating from scratch every time.

<CardGroup cols={2}>
  <Card title="Consistent Results" icon="bullseye">
    Your agent runs proven code that already worked, not a fresh generation roll. Same correct output every time.
  </Card>
  <Card title="30x Faster" icon="bolt">
    Proven code retrieved in ~1s vs 30-180s of regenerating from scratch
  </Card>
  <Card title="Lower Cost" icon="coins">
    Skip token-expensive code generation on tasks your agent has already solved
  </Card>
  <Card title="Community Knowledge" icon="users">
    Public registry of validated code patterns, plus your own private library
  </Card>
</CardGroup>

## The Problem

Production agents chain together 10, 20, 30+ tool calls per run. A freight logistics agent reads a row from the database, pulls a column, checks a Slack channel, cross-references an email, control-F's a date — that's 10 tools before it even has the right context. Then it still has to act on it.

Each tool call is an LLM roundtrip. Each roundtrip can fail. And errors compound across the chain: even if each step has a 98% success rate, a 20-step workflow only has a 67% chance of getting through cleanly. At 50 tools, you're at 36%.

You're paying for tokens, waiting for generation, and getting inconsistent results — for code patterns your agent has already solved hundreds of times before.

## The Solution

Raysurfer caches the code your agent generates. When a similar task comes up, the agent retrieves the entire proven workflow and runs it directly — no LLM regeneration, no trial-and-error loop, no compounding errors.

```
Without Raysurfer:  Task → 30 serial LLM roundtrips → errors compound → maybe works
With Raysurfer:     Task → retrieve proven code → runs immediately → same result every time
```

Think of it as compiling your agent's tool call sequences into reusable code. Once a workflow is proven, the agent doesn't need the LLM anymore for that task — it just runs the code.

<Note>
Queries don't need to be identical — Raysurfer uses semantic matching to find related patterns. "Fetch GitHub repos" and "get trending GitHub projects" return the same proven code.
</Note>

## Why Not Just Use Skills?

Anthropic and other frameworks push "skills" — developer-maintained markdown or code that agents can load. Skills get you most of the way there, but they're **developer-maintained, not AI-maintained.** If you have 50 clients and each client has 20 common tool call patterns, you're building and maintaining 1,000 skills by hand. That's not scalable.

Raysurfer skills are AI-maintained. The agent generates code, executes it, and Raysurfer caches what works. No developer writes or maintains the cached workflows — the agent does it itself, and the best code rises to the top through reputation scoring.

## How It Works

1. **Search for proven code** — Describe your task in natural language. Raysurfer finds code that already solved similar tasks.
2. **Run it** — Retrieved code is proven to work. Your agent runs it immediately.
3. **Build reputation** — Code that produces useful results gets promoted. Code that fails gets deprioritized. The best answers rise to the top.

<Card title="Is Raysurfer right for you?" icon="compass" href="/is-it-right-for-me">
  Raysurfer helps agents running 10+ tool calls per run. Check if your workflow is a fit.
</Card>

<Card title="Ready to get started?" icon="rocket" href="/quickstart">
  Follow the quickstart to integrate Raysurfer in under 5 minutes
</Card>

<Card title="Logging for LLM agents" icon="terminal" href="/logging-for-llm-agents">
  Summary-first hashed logs agents can expand with authenticated curl
</Card>
