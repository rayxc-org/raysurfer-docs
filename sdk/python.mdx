---
title: Python SDK
description: "Drop-in replacement for Claude Agent SDK"
---

## Installation

```bash
pip install raysurfer
```

## Setup

Set your API key:

```bash
export RAYSURFER_API_KEY=your_api_key_here
```

Get your key from the [dashboard](https://raysurfer.com/dashboard/api-keys).

## Usage

Swap your client class and method names. Options come directly from `claude_agent_sdk`:

```python
# Before
from claude_agent_sdk import ClaudeSDKClient, ClaudeAgentOptions

# After
from raysurfer import RaysurferClient
from claude_agent_sdk import ClaudeAgentOptions

options = ClaudeAgentOptions(
    allowed_tools=["Read", "Write", "Bash"],
    system_prompt="You are a helpful assistant.",
)

async with RaysurferClient(options) as client:
    await client.query("Generate quarterly report")
    async for msg in client.response():
        print(msg)
```

## Method Mapping

| Claude SDK | Raysurfer |
|------------|-----------|
| `ClaudeSDKClient(options)` | `RaysurferClient(options)` |
| `await client.query(prompt)` | `await client.query(prompt)` |
| `client.receive_response()` | `client.response()` |

## Options

Options are passed through directly from `claude_agent_sdk.ClaudeAgentOptions`. All standard options work:

```python
from claude_agent_sdk import ClaudeAgentOptions

options = ClaudeAgentOptions(
    allowed_tools=["Read", "Write", "Bash"],
    system_prompt="You are a helpful assistant.",
    model="claude-opus-4-5-20250514",
    max_turns=10,
    cwd="/path/to/working/dir",
    # ... all other ClaudeAgentOptions fields
)
```

Caching is enabled automatically when `RAYSURFER_API_KEY` is set.

## Snippet Retrieval Scope

Control which cached snippets are retrieved using `snips_desired`:

```python
from raysurfer import RaysurferClient
from claude_agent_sdk import ClaudeAgentOptions

options = ClaudeAgentOptions(
    allowed_tools=["Read", "Write", "Bash"],
)

# Include company-level snippets
client = RaysurferClient(
    options,
    snips_desired="company",  # Company-level snippets (Team/Enterprise)
)

# Enterprise: Retrieve client-specific snippets only
client = RaysurferClient(
    options,
    snips_desired="client",   # Client workspace snippets (Enterprise only)
)
```

| Configuration | Required Tier |
|--------------|---------------|
| `snips_desired="company"` | TEAM or ENTERPRISE |
| `snips_desired="client"` | ENTERPRISE only |

## Full Example

```python
import asyncio
import os
from raysurfer import RaysurferClient
from claude_agent_sdk import ClaudeAgentOptions

os.environ["RAYSURFER_API_KEY"] = "your_api_key"

async def main():
    options = ClaudeAgentOptions(
        allowed_tools=["Read", "Write", "Bash"],
        system_prompt="You are a helpful assistant.",
    )

    async with RaysurferClient(options) as client:
        # First run: generates and caches code
        await client.query("Fetch GitHub trending repos")
        async for msg in client.response():
            print(msg)

        # Second run: retrieves from cache (instant)
        await client.query("Fetch GitHub trending repos")
        async for msg in client.response():
            print(msg)

asyncio.run(main())
```

## Without Caching

If `RAYSURFER_API_KEY` is not set, `RaysurferClient` behaves exactly like `ClaudeSDKClient` — no caching, just a pass-through wrapper.

## Low-Level API

For custom integrations, use the `RaySurfer` client directly.

### Complete Low-Level Example with Anthropic API

```python
import anthropic
from raysurfer import RaySurfer
from raysurfer.types import FileWritten, LogFile

client = RaySurfer(api_key="your_raysurfer_api_key")
task = "Fetch GitHub trending repos"

# 1. Retrieve cached code files for a task
result = client.get_code_files(
    task=task,
    top_k=5,
    min_verdict_score=0.3,
)

# result.add_to_llm_prompt contains a pre-formatted string like:
# "
#
# You have access to pre-written code files:
# - .raysurfer_code/github_fetcher.py: Fetches trending repos
# ..."

# Augment your system prompt with cached code context
base_prompt = "You are a helpful coding assistant."
augmented_prompt = base_prompt + result.add_to_llm_prompt

# Make your Anthropic API call with the augmented prompt
anthropic_client = anthropic.Anthropic()
response = anthropic_client.messages.create(
    model="claude-opus-4-5-20250514",
    max_tokens=1024,
    system=augmented_prompt,
    messages=[{"role": "user", "content": "Fetch the top 10 trending GitHub repos"}],
)

print(response.content[0].text)

# 2. Upload new code snippets after execution
#    Voting is triggered automatically when auto_vote is True (default)
files = [FileWritten(path="fetch_repos.py", content="def fetch(): ...")]
client.upload_new_code_snips(
    task=task,
    files_written=files,
    succeeded=True,
    execution_logs="Fetched 10 trending repos successfully",
)

# 2b. Bulk upload prompts/logs/code for sandboxed grading
logs = [LogFile(path="logs/run.log", content="Task completed", encoding="utf-8")]
client.upload_bulk_code_snips(
    prompts=["Build a CLI tool", "Add CSV support"],
    files_written=[FileWritten(path="cli.py", content="def main(): ...")],
    log_files=logs,
    auto_vote=True,
)

# 3. (Optional) Vote on a cached snippet manually
#    Only needed if you want explicit control — upload_new_code_snips already votes by default
client.vote_code_snip(
    task=task,
    code_block_id=result.files[0].code_block_id,
    code_block_name=result.files[0].filename,
    code_block_description=result.files[0].description,
    succeeded=True,
)
```

### Response Fields

The `get_code_files()` response includes:

| Field | Type | Description |
|-------|------|-------------|
| `files` | `list[CodeFile]` | Retrieved code files with metadata |
| `task` | `str` | The task that was searched |
| `total_found` | `int` | Total matches found |
| `add_to_llm_prompt` | `str` | Pre-formatted string to append to your LLM system prompt |

Each `CodeFile` contains `code_block_id`, `filename`, `source`, `description`, `verdict_score`, `thumbs_up`, `thumbs_down`, and `similarity_score`.

### Async Version

```python
import anthropic
from raysurfer import AsyncRaySurfer
from raysurfer.types import FileWritten

async with AsyncRaySurfer(api_key="your_api_key") as client:
    # 1. Retrieve cached code
    result = await client.get_code_files(task="Fetch GitHub trending repos")

    # 2. Use add_to_llm_prompt to augment your LLM call
    augmented_prompt = "You are helpful." + result.add_to_llm_prompt

    # 3. Upload new code after execution (voting triggered by default)
    files = [FileWritten(path="fetch_repos.py", content="def fetch(): ...")]
    await client.upload_new_code_snips(
        task=task,
        files_written=files,
        succeeded=True,
        execution_logs="Fetched 10 trending repos successfully",
    )

    # 4. (Optional) Vote on snippet manually — only if you need explicit control
    await client.vote_code_snip(
        task=task,
        code_block_id=result.files[0].code_block_id,
        code_block_name=result.files[0].filename,
        code_block_description=result.files[0].description,
        succeeded=True,
    )
```

### Method Reference

| Method | Description |
|--------|-------------|
| `search(task, top_k, min_verdict_score, prefer_complete)` | Unified search for cached code (recommended) |
| `get_code_files(task, top_k, min_verdict_score, prefer_complete, cache_dir)` | Retrieve cached code files with `add_to_llm_prompt` for LLM augmentation |
| `get_code_snips(task, top_k, min_verdict_score)` | Retrieve cached code snippets by semantic search |
| `upload_new_code_snips(task, files_written, succeeded, auto_vote, execution_logs)` | Store new code files for future reuse (auto-votes by default) |
| `upload_bulk_code_snips(prompts, files_written, log_files, auto_vote)` | Bulk upload prompts/logs/code for sandboxed grading (votes each file) |
| `vote_code_snip(task, code_block_id, name, description, succeeded)` | Vote on snippet usefulness (triggers async backend voting) |
